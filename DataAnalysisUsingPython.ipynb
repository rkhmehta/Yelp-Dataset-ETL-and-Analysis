{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-04T16:33:11.178645Z","iopub.status.busy":"2023-11-04T16:33:11.177728Z","iopub.status.idle":"2023-11-04T16:33:12.196938Z","shell.execute_reply":"2023-11-04T16:33:12.195046Z","shell.execute_reply.started":"2023-11-04T16:33:11.178572Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:33:12.200707Z","iopub.status.busy":"2023-11-04T16:33:12.199985Z","iopub.status.idle":"2023-11-04T16:33:18.075243Z","shell.execute_reply":"2023-11-04T16:33:18.073931Z","shell.execute_reply.started":"2023-11-04T16:33:12.200657Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"yelp_academic_dataset_checkin.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","checkin_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:33:18.079276Z","iopub.status.busy":"2023-11-04T16:33:18.076663Z","iopub.status.idle":"2023-11-04T16:33:24.505646Z","shell.execute_reply":"2023-11-04T16:33:24.504482Z","shell.execute_reply.started":"2023-11-04T16:33:18.079225Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"yelp_academic_dataset_business.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","business_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:33:24.507430Z","iopub.status.busy":"2023-11-04T16:33:24.507099Z","iopub.status.idle":"2023-11-04T16:36:08.912331Z","shell.execute_reply":"2023-11-04T16:36:08.911168Z","shell.execute_reply.started":"2023-11-04T16:33:24.507400Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"yelp_academic_dataset_review.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","review_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:36:08.915828Z","iopub.status.busy":"2023-11-04T16:36:08.915473Z","iopub.status.idle":"2023-11-04T16:36:19.516108Z","shell.execute_reply":"2023-11-04T16:36:19.514677Z","shell.execute_reply.started":"2023-11-04T16:36:08.915799Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"yelp_academic_dataset_tip.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","tip_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:36:19.518436Z","iopub.status.busy":"2023-11-04T16:36:19.518074Z","iopub.status.idle":"2023-11-04T16:37:58.455886Z","shell.execute_reply":"2023-11-04T16:37:58.454550Z","shell.execute_reply.started":"2023-11-04T16:36:19.518405Z"},"trusted":true},"outputs":[],"source":["data_file = open(\"yelp_academic_dataset_user.json\")\n","data = []\n","for line in data_file:\n","  data.append(json.loads(line))\n","user_df = pd.DataFrame(data)\n","data_file.close()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:37:58.458151Z","iopub.status.busy":"2023-11-04T16:37:58.457752Z","iopub.status.idle":"2023-11-04T16:37:58.477319Z","shell.execute_reply":"2023-11-04T16:37:58.474753Z","shell.execute_reply.started":"2023-11-04T16:37:58.458117Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0         Doctors, Traditional Chinese Medicine, Naturop...\n","1         Shipping Centers, Local Services, Notaries, Ma...\n","2         Department Stores, Shopping, Fashion, Home & G...\n","3         Restaurants, Food, Bubble Tea, Coffee & Tea, B...\n","4                                 Brewpubs, Breweries, Food\n","                                ...                        \n","150341                           Nail Salons, Beauty & Spas\n","150342    Pets, Nurseries & Gardening, Pet Stores, Hobby...\n","150343    Shopping, Jewelry, Piercing, Toy Stores, Beaut...\n","150344    Fitness/Exercise Equipment, Eyewear & Optician...\n","150345    Beauty & Spas, Permanent Makeup, Piercing, Tattoo\n","Name: categories, Length: 150346, dtype: object\n"]}],"source":["print(business_df[\"categories\"])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:37:58.480057Z","iopub.status.busy":"2023-11-04T16:37:58.478939Z","iopub.status.idle":"2023-11-04T16:38:50.074483Z","shell.execute_reply":"2023-11-04T16:38:50.073176Z","shell.execute_reply.started":"2023-11-04T16:37:58.480018Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                   business_id             business_category\n","0       Pns2l4eNsfO8kk83dixA6A                       Doctors\n","0       Pns2l4eNsfO8kk83dixA6A  Traditional Chinese Medicine\n","0       Pns2l4eNsfO8kk83dixA6A         Naturopathic/Holistic\n","0       Pns2l4eNsfO8kk83dixA6A                   Acupuncture\n","0       Pns2l4eNsfO8kk83dixA6A              Health & Medical\n","...                        ...                           ...\n","150344  mtGm22y5c2UHNXDFAjaPNw                         Bikes\n","150345  jV_XOycEzSlTx-65W906pg                 Beauty & Spas\n","150345  jV_XOycEzSlTx-65W906pg              Permanent Makeup\n","150345  jV_XOycEzSlTx-65W906pg                      Piercing\n","150345  jV_XOycEzSlTx-65W906pg                        Tattoo\n","\n","[668695 rows x 2 columns]\n"]}],"source":["def split_and_explode(row):\n","    categories = row['categories']\n","    if categories is not None and categories.strip() != '':\n","        categories = categories.split(', ')\n","        return pd.Series({'business_id': row['business_id'], 'business_category': categories})\n","    else:\n","        return pd.Series({'business_id': row['business_id'], 'business_category': []})\n","\n","# Apply the function to split and explode categories\n","business_categories = business_df.apply(split_and_explode, axis=1)\n","\n","# Explode the list of business categories\n","business_categories = business_categories.explode('business_category')\n","\n","# Display the resulting DataFrame\n","print(business_categories)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:38:50.076466Z","iopub.status.busy":"2023-11-04T16:38:50.076041Z","iopub.status.idle":"2023-11-04T16:39:41.776823Z","shell.execute_reply":"2023-11-04T16:39:41.775567Z","shell.execute_reply.started":"2023-11-04T16:38:50.076436Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                   business_id          business_attribute\n","0       Pns2l4eNsfO8kk83dixA6A           ByAppointmentOnly\n","1       mpf3x-BjTdTEA3yCZrAYPw  BusinessAcceptsCreditCards\n","2       tUFrWirKiKi_TAnsVWINQQ                 BikeParking\n","2       tUFrWirKiKi_TAnsVWINQQ  BusinessAcceptsCreditCards\n","2       tUFrWirKiKi_TAnsVWINQQ      RestaurantsPriceRange2\n","...                        ...                         ...\n","150345  jV_XOycEzSlTx-65W906pg  BusinessAcceptsCreditCards\n","150345  jV_XOycEzSlTx-65W906pg             BusinessParking\n","150345  jV_XOycEzSlTx-65W906pg                 BikeParking\n","150345  jV_XOycEzSlTx-65W906pg                        WiFi\n","150345  jV_XOycEzSlTx-65W906pg           ByAppointmentOnly\n","\n","[1220564 rows x 2 columns]\n"]}],"source":["def extract_and_explode(row):\n","    attributes = row['attributes']\n","    if isinstance(attributes, dict):\n","        attribute_list = [key for key, value in attributes.items() if value]\n","        return pd.Series({'business_id': row['business_id'], 'business_attribute': attribute_list})\n","    else:\n","        return pd.Series({'business_id': row['business_id'], 'business_attribute': []})\n","\n","# Apply the function to extract and explode attributes\n","business_attributes = business_df.apply(extract_and_explode, axis=1)\n","\n","# Explode the list of business attributes\n","business_attributes = business_attributes.explode('business_attribute')\n","\n","# Display the resulting DataFrame\n","print(business_attributes)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:41.778595Z","iopub.status.busy":"2023-11-04T16:39:41.778010Z","iopub.status.idle":"2023-11-04T16:39:55.363714Z","shell.execute_reply":"2023-11-04T16:39:55.362517Z","shell.execute_reply.started":"2023-11-04T16:39:41.778528Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                   business_id day_of_week open_time close_time\n","0       mpf3x-BjTdTEA3yCZrAYPw      Monday       0:0        0:0\n","1       mpf3x-BjTdTEA3yCZrAYPw     Tuesday       8:0      18:30\n","2       mpf3x-BjTdTEA3yCZrAYPw   Wednesday       8:0      18:30\n","3       mpf3x-BjTdTEA3yCZrAYPw    Thursday       8:0      18:30\n","4       mpf3x-BjTdTEA3yCZrAYPw      Friday       8:0      18:30\n","...                        ...         ...       ...        ...\n","801010  jV_XOycEzSlTx-65W906pg     Tuesday      12:0       19:0\n","801011  jV_XOycEzSlTx-65W906pg   Wednesday      12:0       19:0\n","801012  jV_XOycEzSlTx-65W906pg    Thursday      12:0       19:0\n","801013  jV_XOycEzSlTx-65W906pg      Friday      12:0       19:0\n","801014  jV_XOycEzSlTx-65W906pg    Saturday      12:0       19:0\n","\n","[801015 rows x 4 columns]\n"]}],"source":["rows = []\n","\n","# Define the days of the week\n","days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n","\n","# Iterate over rows in the DataFrame\n","for _, row in business_df.iterrows():\n","    business_id = row['business_id']\n","    hours = row['hours']\n","    \n","    if hours is not None:\n","        for day_of_week in days_of_week:\n","            time_range = hours.get(day_of_week)\n","            if time_range:\n","                open_time, close_time = time_range.split('-')\n","                rows.append({\n","                    'business_id': business_id,\n","                    'day_of_week': day_of_week,\n","                    'open_time': open_time,\n","                    'close_time': close_time\n","                })\n","\n","# Create a DataFrame from the list of rows\n","business_hours = pd.DataFrame(rows)\n","\n","# Display the resulting DataFrame\n","print(business_hours)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:55.365659Z","iopub.status.busy":"2023-11-04T16:39:55.365348Z","iopub.status.idle":"2023-11-04T16:39:55.724279Z","shell.execute_reply":"2023-11-04T16:39:55.721559Z","shell.execute_reply.started":"2023-11-04T16:39:55.365631Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                       categories  count\n","3479           Restaurants, Pizza    154\n","2644           Pizza, Restaurants    124\n","3006         Restaurants, Chinese     89\n","976          Chinese, Restaurants     84\n","3324         Restaurants, Italian     43\n","3402         Restaurants, Mexican     42\n","2306         Mexican, Restaurants     39\n","2076         Italian, Restaurants     39\n","2746  Restaurants, American (New)     36\n","87    American (New), Restaurants     34\n"]}],"source":["# QUERY 1\n","filtered_business = business_df[(business_df['city'] == 'Philadelphia') & (business_df['business_id'].isin(business_categories[business_categories['business_category'] == 'Restaurants']['business_id']))]\n","\n","# Group and count business categories\n","result = filtered_business[filtered_business['business_id'].isin(business_categories['business_id'])].groupby('categories').size().reset_index(name='count')\n","\n","# Sort by count in descending order and limit to top 10\n","result = result.sort_values(by='count', ascending=False).head(10)\n","\n","print(result)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:55.726617Z","iopub.status.busy":"2023-11-04T16:39:55.726142Z","iopub.status.idle":"2023-11-04T16:39:56.663869Z","shell.execute_reply":"2023-11-04T16:39:56.663009Z","shell.execute_reply.started":"2023-11-04T16:39:55.726582Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                         name   stars  review_count\n","3632  Reading Terminal Market  4.5000          5721\n","3317     Pat's King of Steaks  3.0000          4250\n","3801           Sabrina's Café  4.0000          3730\n","1718          Green Eggs Café  3.7500          3531\n","1614            Geno's Steaks  1.7500          3406\n","1327                   El Vez  4.0000          3187\n","5032                    Zahav  4.5000          3065\n","1166           Dim Sum Garden  4.0000          3049\n","353                  Barbuzzo  4.5000          2893\n","1420           Federal Donuts  4.1875          2811\n"]}],"source":["#QUERY 2\n","merged_df = pd.merge(business_df, business_categories, on='business_id')\n","\n","# Filter businesses in Philadelphia with the 'Restaurants' category\n","filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (merged_df['business_category'] == 'Restaurants')]\n","\n","# Group by restaurant names and calculate average rating and total review count\n","result = filtered_df.groupby('name').agg({\n","    'stars': 'mean',\n","    'review_count': 'sum'\n","}).reset_index()\n","\n","# Sort by total reviews and average rating in descending order\n","result = result.sort_values(by=['review_count', 'stars'], ascending=[False, False])\n","\n","# Limit to the top 10 restaurants\n","result = result.head(10)\n","\n","print(result)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:56.665735Z","iopub.status.busy":"2023-11-04T16:39:56.665371Z","iopub.status.idle":"2023-11-04T16:39:57.630928Z","shell.execute_reply":"2023-11-04T16:39:57.629626Z","shell.execute_reply.started":"2023-11-04T16:39:56.665703Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                  name  review_count\n","636969         Reading Terminal Market          5721\n","506489            Pat's King of Steaks          4250\n","254368                   Geno's Steaks          3401\n","585425                          El Vez          3187\n","138595                           Zahav          3065\n","288179                        Barbuzzo          2893\n","89200                             Parc          2761\n","237140                  Jim's South St          2736\n","163293  Dalessandro’s Steaks & Hoagies          2686\n","664178                 Green Eggs Café          2679\n"]}],"source":["#QUERY 3\n","merged_df = pd.merge(business_df, business_categories, on='business_id')\n","\n","# Filter businesses in Philadelphia with the 'Restaurants' category\n","filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (merged_df['business_category'] == 'Restaurants')]\n","\n","# Select restaurant name and total review count\n","result = filtered_df[['name', 'review_count']]\n","\n","# Sort by total reviews in descending order\n","result = result.sort_values(by='review_count', ascending=False)\n","\n","# Limit to the top 10 restaurants\n","result = result.head(10)\n","\n","print(result)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:57.634970Z","iopub.status.busy":"2023-11-04T16:39:57.634605Z","iopub.status.idle":"2023-11-04T16:39:58.587159Z","shell.execute_reply":"2023-11-04T16:39:58.585932Z","shell.execute_reply.started":"2023-11-04T16:39:57.634927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  Restaurant_Status  Total_Count\n","0            Closed         2327\n","1              Open         3525\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/9x/_ytz9d695dbc1bz3dqw1zf6w0000gn/T/ipykernel_16929/447802183.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_df['Restaurant_Status'] = filtered_df['is_open'].apply(lambda x: 'Open' if x == 1 else 'Closed')\n"]}],"source":["#QUERY 4\n","merged_df = pd.merge(business_df, business_categories, on='business_id')\n","\n","# Filter businesses in Philadelphia with the 'Restaurants' category\n","filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (merged_df['business_category'] == 'Restaurants')]\n","\n","# Create a new column 'Restaurant_Status' based on 'is_open'\n","filtered_df['Restaurant_Status'] = filtered_df['is_open'].apply(lambda x: 'Open' if x == 1 else 'Closed')\n","\n","# Group by 'Restaurant_Status' and count total occurrences\n","result = filtered_df.groupby('Restaurant_Status').size().reset_index(name='Total_Count')\n","\n","# Rename the columns to match the SQL query\n","result = result.rename(columns={'Restaurant_Status': 'Restaurant_Status', 'Total_Count': 'Total_Count'})\n","\n","print(result)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:39:58.589825Z","iopub.status.busy":"2023-11-04T16:39:58.589007Z","iopub.status.idle":"2023-11-04T16:40:04.297799Z","shell.execute_reply":"2023-11-04T16:40:04.294247Z","shell.execute_reply.started":"2023-11-04T16:39:58.589778Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Hours Open: 9.131488203266787\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/9x/_ytz9d695dbc1bz3dqw1zf6w0000gn/T/ipykernel_16929/3596289230.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_df['hours_open'] = filtered_df.apply(calculate_hours_open, axis=1)\n"]}],"source":["#QUERY 5\n","from datetime import datetime\n","merged_df = pd.merge(business_df, business_hours, on='business_id')\n","merged_df = pd.merge(merged_df, business_categories, on='business_id')\n","\n","# Filter businesses in Philadelphia with the 'Restaurants' category\n","filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (filtered_df['business_category'] == 'Restaurants')]\n","\n","# Function to calculate hours open for each business\n","def calculate_hours_open(row):\n","    open_time = datetime.strptime(row['open_time'], '%H:%M')\n","    close_time = datetime.strptime(row['close_time'], '%H:%M')\n","\n","    if close_time >= open_time:\n","        time_diff = (close_time - open_time).seconds / 3600  # Convert seconds to hours\n","    else:\n","        end_of_day = datetime.strptime('23:59', '%H:%M')\n","        time_diff = ((end_of_day - open_time).seconds + (close_time - datetime.strptime('00:00', '%H:%M')).seconds) / 3600  # Convert seconds to hours\n","    return time_diff\n","\n","# Calculate hours open for each business\n","filtered_df['hours_open'] = filtered_df.apply(calculate_hours_open, axis=1)\n","\n","# Calculate the average hours open for all businesses\n","average_hours_open = filtered_df['hours_open'].mean()\n","\n","print(\"Average Hours Open:\", average_hours_open)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:40:04.299653Z","iopub.status.busy":"2023-11-04T16:40:04.299171Z","iopub.status.idle":"2023-11-04T16:40:06.100257Z","shell.execute_reply":"2023-11-04T16:40:06.098858Z","shell.execute_reply.started":"2023-11-04T16:40:04.299617Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                name  Total_Checkins\n","163293       Sweet Lucy's Smokehouse            1175\n","87                               BAP             221\n","72                          Tuna Bar             172\n","227812    World Wide Aquarium & Pets              30\n","263501            CrossFit Fairmount              29\n","52146   New Lee's Chinese Restaurant              20\n","570322         Alif Brew & Mini Mart              11\n","260698   O Rei Da Picanha Steakhouse               8\n","206756             Callowhill Greens               7\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/9x/_ytz9d695dbc1bz3dqw1zf6w0000gn/T/ipykernel_16929/753077826.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (filtered_df['business_category'] == 'Restaurants')]\n","/var/folders/9x/_ytz9d695dbc1bz3dqw1zf6w0000gn/T/ipykernel_16929/753077826.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_df['Total_Checkins'] = filtered_df.apply(calculate_total_checkins, axis=1)\n"]}],"source":["#QUERY 6\n","merged_df = pd.merge(business_df, checkin_df, on='business_id')\n","merged_df = pd.merge(merged_df, business_categories, on='business_id')\n","\n","# Filter businesses in Philadelphia with the 'Restaurants' category\n","filtered_df = merged_df[(merged_df['city'] == 'Philadelphia') & (filtered_df['business_category'] == 'Restaurants')]\n","\n","# Function to calculate total check-ins\n","def calculate_total_checkins(row):\n","    return len(row['date'].split(','))\n","\n","# Calculate total check-ins for each restaurant\n","filtered_df['Total_Checkins'] = filtered_df.apply(calculate_total_checkins, axis=1)\n","\n","# Sort the DataFrame by 'Total_Checkins' in descending order\n","sorted_df = filtered_df.sort_values(by='Total_Checkins', ascending=False)\n","\n","# Select the top 10 restaurants with the highest total check-ins\n","top_10_restaurants = sorted_df.head(10)\n","\n","print(top_10_restaurants[['name', 'Total_Checkins']])"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T16:40:06.103026Z","iopub.status.busy":"2023-11-04T16:40:06.102118Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0                            Avengers time with the ladies.\n","1         They have lots of good deserts and tasty cuban...\n","2                    It's open even when you think it isn't\n","3                                 Very decent fried chicken\n","4                    Appetizers.. platter special for lunch\n","                                ...                        \n","908910                Disappointed in one of your managers.\n","908911                              Great food and service.\n","908912                                  Love their Cubans!!\n","908913                              Great pizza great price\n","908914                    Food is good value but a bit hot!\n","Name: text, Length: 908915, dtype: object\n"]}],"source":["print(tip_df[\"text\"])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top Reviewers:\n","                        user_id  stars\n","0        ---1lKK3aKOuomHnwAkAow    5.0\n","1027402  W17zbNSLF0DW2uu0Oy4IXA    5.0\n","1027373  W13JwV5DJCYds57kiu4h-A    5.0\n","1027375  W13OsqHpHSAtbMK1De9XXQ    5.0\n","1027380  W14KPPpnz3xi5Eqn0Q38SA    5.0\n","1027382  W14SFFHOCZa6GQB5s8Gh5Q    5.0\n","1027383  W14ZeF164SCqZ6QRniclmQ    5.0\n","1027385  W14kmIm0kGWa9eDPE_JFjQ    5.0\n","1027387  W15-0kDbkFCYxNpDcaDEuQ    5.0\n","1027389  W152UVHDpb237E71KMiArA    5.0\n"]}],"source":["#QUERY 7\n","user_avg_ratings = review_df.groupby('user_id')['stars'].mean().reset_index()\n","\n","# Sort users based on their average review rating in descending order\n","sorted_users = user_avg_ratings.sort_values(by='stars', ascending=False)\n","\n","# Select the top reviewers with the highest average ratings\n","top_reviewers = sorted_users.head(10)\n","\n","# Print the top reviewers\n","print(\"Top Reviewers:\")\n","print(top_reviewers)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Restaurant Categories with the Most Tips:\n","                                    Restaurant_Category  Number_ofTips\n","761   Candy Stores, Shopping, Department Stores, Fas...            827\n","2422                                 Pizza, Restaurants            703\n","3187                                 Restaurants, Pizza            700\n","3041                               Restaurants, Italian            573\n","3117                               Restaurants, Mexican            567\n","...                                                 ...            ...\n","3325  Restaurants, Southern, Fast Food, Chicken Wing...              1\n","2752                 Restaurants, Chinese, Asian Fusion              1\n","2500  Puerto Rican, Spanish, Cuban, Caribbean, Resta...              1\n","3328          Restaurants, Spanish, Seafood, Portuguese              1\n","3556  Sandwiches, Restaurants, Coffee & Tea, Food, V...              1\n","\n","[3960 rows x 2 columns]\n"]}],"source":["#QUERY 8\n","filtered_business = business_df[(business_df['city'] == 'Philadelphia') & (business_df['categories'].str.contains('restaurants', case=False, regex=True))]\n","\n","# Merge the 'filtered_business' DataFrame with the 'tip' DataFrame\n","merged_df = pd.merge(tip_df, filtered_business, on='business_id', how='inner')\n","\n","# Group by restaurant categories and count the number of tips\n","category_engagement = merged_df.groupby('categories')['business_id'].count().reset_index()\n","category_engagement.rename(columns={'categories': 'Restaurant_Category', 'business_id': 'Number_ofTips'}, inplace=True)\n","\n","# Sort by 'Number_ofTips' in descending order\n","category_engagement = category_engagement.sort_values(by='Number_ofTips', ascending=False)\n","\n","# Print the restaurant categories with the highest number of tips\n","print(\"Restaurant Categories with the Most Tips:\")\n","print(category_engagement)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                               Restaurant_Name  NumberOfTips\n","6095  Philadelphia International Airport - PHL          1011\n","6605                   Reading Terminal Market           827\n","7573                                 Starbucks           688\n","6963                            Sabrina's Café           499\n","2024            Dalessandro’s Steaks & Hoagies           460\n","3207                           Green Eggs Café           421\n","5889                      Pat's King of Steaks           400\n","2307                                   Dunkin'           393\n","2179                            Dim Sum Garden           382\n","3328                               Han Dynasty           380\n"]}],"source":["#QUERY 9\n","filtered_business = business_df[business_df['city'] == 'Philadelphia']\n","\n","# Merge the 'filtered_business' DataFrame with the 'tip' DataFrame using an inner join\n","merged_df = filtered_business.merge(tip_df, on='business_id', how='inner')\n","\n","# Group by restaurant names and count the number of tips\n","result = merged_df.groupby('name')['business_id'].count().reset_index()\n","result.rename(columns={'name': 'Restaurant_Name', 'business_id': 'NumberOfTips'}, inplace=True)\n","\n","# Sort by 'NumberOfTips' in descending order and limit to the top 10\n","result = result.sort_values(by='NumberOfTips', ascending=False).head(10)\n","\n","print(result)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                 review_id                 user_id             business_id  \\\n","0   Hr_-94dbvGOulwXoVC0iXQ  rVo3owIvz-iJhBb9A9TXLg  TGuMpvsCKuAcGER8cGXhWg   \n","1   gR0cs1X8aBKCMowmIEdopw  mzUTfAvbxEfc9lqjl7BtOg  TGuMpvsCKuAcGER8cGXhWg   \n","2   xuI0hFE6WPPwQFrJSfQ2AA  uBtcU_YD2rMYawa_Rc-fpw  TGuMpvsCKuAcGER8cGXhWg   \n","3   mGyOuES3YOSFHoHkCJgDMw  j5YS-J6kytVelaMYUKFNlg  TGuMpvsCKuAcGER8cGXhWg   \n","4   FD2zBDL98jFhoM087rCFzw  yPM6YRXJ36yPej_XKjtlBw  TGuMpvsCKuAcGER8cGXhWg   \n","..                     ...                     ...                     ...   \n","93  41xWoFIy5ltVAZfEe8meqA  VFR3Q5Uk3CfEQXAW6nqxUw  TGts2jHdAF0MXllTBuUaIg   \n","94  ASLg93KQesMCtV04GFlD5Q  m8HWHV3wFkYe85I4K-b6Gw  TGts2jHdAF0MXllTBuUaIg   \n","95  xbL9I_2RkQv1hp4Vcctxug  LREYVbQ2KkzmpJhQOfMrgQ  TGts2jHdAF0MXllTBuUaIg   \n","96  sVhfL_sOcENQEkTGi-zE0w  eJDcMASAcKB_fYXug5SH0g  TGts2jHdAF0MXllTBuUaIg   \n","97  gU48OdJyZY38J3EK6Cdq2Q  wVSz-wislRKONqDCWcMnhQ  TGts2jHdAF0MXllTBuUaIg   \n","\n","    stars_x  useful  funny  cool  \\\n","0       1.0       0      0     0   \n","1       1.0       6      0     0   \n","2       1.0       4      0     1   \n","3       1.0       8      0     0   \n","4       1.0       0      0     0   \n","..      ...     ...    ...   ...   \n","93      1.0       0      0     0   \n","94      1.0       0      0     0   \n","95      1.0       1      0     0   \n","96      1.0       0      0     0   \n","97      1.0       0      0     0   \n","\n","                                                 text                 date  \\\n","0   Ask who will read your x-ray!  DO NOT USE THIS...  2019-01-06 17:03:22   \n","1   Radiology Alliance has to have the worst custo...  2018-01-11 21:15:05   \n","2   Recently found an account from these guys had ...  2019-02-28 23:12:23   \n","3   Based on the other review, this seems to be th...  2017-11-20 16:17:17   \n","4   These folks are liars and thieves. Pay attenti...  2021-12-22 15:44:04   \n","..                                                ...                  ...   \n","93  I'm a recent customer.  I called 6, yes SIX, t...  2020-06-22 04:57:07   \n","94  One week they missed my recycling pick up. Nex...  2020-02-11 17:44:37   \n","95  Horrible customer service. It has been over 4 ...  2019-07-19 23:35:22   \n","96  Missed recycling pickups are the norm. I calle...  2021-08-30 13:29:24   \n","97  Have called 5 times to schedule recycling pick...  2021-08-20 20:51:41   \n","\n","    stars_y  \n","0       1.0  \n","1       1.0  \n","2       1.0  \n","3       1.0  \n","4       1.0  \n","..      ...  \n","93      1.0  \n","94      1.0  \n","95      1.0  \n","96      1.0  \n","97      1.0  \n","\n","[98 rows x 10 columns]\n"]}],"source":["filtered_business = business_df[(business_df['city'] == 'Philadelphia') & (business_df['categories'].str.contains('restaurants', case=False, regex=True))]\n","\n","# Calculate the average rating for each restaurant\n","restaurant_avg_ratings = review_df.groupby('business_id')['stars'].mean().reset_index()\n","\n","# Sort the restaurants by average rating in ascending order\n","sorted_restaurants = restaurant_avg_ratings.sort_values(by='stars')\n","\n","# Select the 10 lowest-rated restaurants\n","lowest_rated_restaurants = sorted_restaurants.head(10)\n","\n","# Filter reviews for the 10 lowest-rated restaurants\n","reviews_for_lowest_rated = pd.merge(review_df, lowest_rated_restaurants, on='business_id', how='inner')\n","\n","# Display reviews for the 10 lowest-rated restaurants\n","print(reviews_for_lowest_rated)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
